{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c86194b2",
   "metadata": {},
   "source": [
    "<img src=\"kiitLogo.png\" alt=\"KIIT Logo\" style=\"float:left; padding-right:10px; width: 150px;\">\n",
    "\n",
    "<h1 align=\"center\"><a href=\"https://kiit.ac.in/\" style=\"text-decoration:none; color:black; font-size:38px;\">Kalinga Institute of Industrial Technology</a></h1>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d861bed8",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"><a href=\"https://example.com\" style=\"text-decoration:none; color:black;\">Exploring Dimensionality Reduction with Autoencoders</a></h1>\n",
    "\n",
    "<p align=\"center\" style=\"text-align: center;\">by <a href=\"https://www.linkedin.com/in/vishal-singh/\">Vishal Singh</a>, <a href=\"https://www.linkedin.com/in/vedant-kumar/\">Vedant Kumar</a>, and <a href=\"https://www.linkedin.com/in/m-aditya/\">M. Aditya</a></p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabfa3ba",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this project, we explore dimensionality reduction using autoencoders, a powerful technique in machine learning for compressing high-dimensional data into a lower-dimensional representation while retaining essential information.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5855f829",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "The primary objective of this project is to demonstrate the effectiveness of autoencoders for dimensionality reduction tasks. Specifically, we aim to:\n",
    "\n",
    "- Understand the principles of dimensionality reduction and its importance in data preprocessing.\n",
    "- Compare traditional methods like PCA with autoencoders.\n",
    "- Implement an autoencoder model using TensorFlow.\n",
    "- Evaluate the performance of the autoencoder on synthetic data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec415296",
   "metadata": {},
   "source": [
    "##  Dimensionality Reduction\n",
    "\n",
    "The transformation of data from a high-dimensional space into a meaningful low-dimensional space, which ideally corresponds to the intrinsic dimensionality of the original data, is referred to as **dimensionality reduction**. This transformation is important in several domains because it mitigates undesired properties of high-dimensional spaces such as the curse of dimensionality.\n",
    "\n",
    "Traditionally, dimensionality reduction is performed using linear techniques such as **Principal Components Analysis (PCA)**, which is one of the most used statistical techniques in behavioral sciences and is a standard part of measure development.\n",
    "\n",
    "However, assumptions required for PCA are not always satisfied. PCA assumes that the relationships between variables are linear, and all variables should be assessed on an interval or ratio level of measurement. Therefore, PCA may not always be the most appropriate method of analysis.\n",
    "\n",
    "In contrast to the traditional linear techniques for dimensionality reduction, machine learning techniques can deal with complex nonlinear data, and they represent a valuable alternative to classical methods. Among others, **Autoencoders** seem a valuable alternative to PCA for dimensionality reduction.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7894bb",
   "metadata": {},
   "source": [
    "\n",
    "## Autoencoders: A Nonlinear Approach to Dimensionality Reduction\n",
    "\n",
    "**Autoencoder**, also called auto-associative neural network, is a multi-layer perceptron having the same number of outputs as inputs, designed to learn an approximation to the identity function, so as the output is as similar to the input as possible. This is achieved by minimizing an error function which captures the degree of mismatch between the input vectors and their reconstructions.\n",
    "\n",
    "Autoencoder has the advantage of not being limited to linear transformations and can learn more complicated relations between visible and hidden units, although it contains standard principal component analysis as a special case. However, unlike PCA, the coordinates of the output of the bottleneck are correlated and are not sorted in descending order of variance. Moreover, computationally intensive nonlinear optimization techniques are required for training.\n",
    "\n",
    "Autoencoders offer the flexibility to capture complex, nonlinear relationships in data, making them well-suited for dimensionality reduction tasks where linear techniques may be insufficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcf1ee1",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"AE.png\" alt=\"AutEncoder\" width=\"50%\" height=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dddbb1e",
   "metadata": {},
   "source": [
    "## Code Implementation\n",
    "Let's start by importing necessary libraries and defining the autoencoder model.\n",
    "### Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3ea3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925eeb95",
   "metadata": {},
   "source": [
    "### Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8c999b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Batch_size = 64  # Number of samples per mini-batch\n",
    "num_iterations = 200  # Number of training iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f8fae5",
   "metadata": {},
   "source": [
    "### Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e639f70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from CSV\n",
    "def load_data(file_path):\n",
    "    \"\"\"\n",
    "    Function to load data from a CSV file.\n",
    "    \n",
    "    Parameters:\n",
    "        file_path (str): Path to the CSV file.\n",
    "        \n",
    "    Returns:\n",
    "        input_data (numpy.ndarray): Input features.\n",
    "        output_data (numpy.ndarray): Output features.\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(file_path)\n",
    "    # Assuming the first 5 columns are input and output features\n",
    "    input_data = data.iloc[:, :5].values\n",
    "    output_data = data.iloc[:, :5].values\n",
    "    return input_data, output_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32b96b4",
   "metadata": {},
   "source": [
    "### Define the Autoencoder Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9f68f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(tf.keras.Model):\n",
    "    def __init__(self, input_dim, bottleneck_dim):\n",
    "        \"\"\"\n",
    "        Class constructor to initialize the Autoencoder model.\n",
    "        \n",
    "        Parameters:\n",
    "            input_dim (int): Dimensionality of input data.\n",
    "            bottleneck_dim (int): Dimensionality of the bottleneck layer.\n",
    "        \"\"\"\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.bottleneck_dim = bottleneck_dim\n",
    "        \n",
    "        # Encoder layers\n",
    "        self.encoder_layers = []\n",
    "        for i in range(input_dim - 1, bottleneck_dim - 1, -1):\n",
    "            self.encoder_layers.append(tf.keras.layers.Dense(units=i, activation='relu'))\n",
    "        \n",
    "        # Bottleneck layer\n",
    "        self.bottleneck_layer = tf.keras.layers.Dense(units=bottleneck_dim, activation='relu')\n",
    "        \n",
    "        # Decoder layers\n",
    "        self.decoder_layers = []\n",
    "        for i in range(bottleneck_dim + 1, input_dim + 1):\n",
    "            self.decoder_layers.append(tf.keras.layers.Dense(units=i, activation='relu'))\n",
    "        \n",
    "        # Output layer\n",
    "        self.output_layer = tf.keras.layers.Dense(units=input_dim, activation='sigmoid')\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        Forward pass of the Autoencoder model.\n",
    "        \n",
    "        Parameters:\n",
    "            inputs (tf.Tensor): Input data.\n",
    "        \n",
    "        Returns:\n",
    "            reconstructed (tf.Tensor): Reconstructed output data.\n",
    "        \"\"\"\n",
    "        # Encoder pass\n",
    "        x = inputs\n",
    "        for layer in self.encoder_layers:\n",
    "            x = layer(x)\n",
    "        \n",
    "        # Bottleneck pass\n",
    "        x = self.bottleneck_layer(x)\n",
    "        \n",
    "        # Decoder pass\n",
    "        for layer in self.decoder_layers:\n",
    "            x = layer(x)\n",
    "        \n",
    "        # Output pass\n",
    "        reconstructed = self.output_layer(x)\n",
    "        return reconstructed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce95b164",
   "metadata": {},
   "source": [
    "### Function to Train the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ede50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(autoencoder, input_data, output_data):\n",
    "    \"\"\"\n",
    "    Function to train the Autoencoder model.\n",
    "    \n",
    "    Parameters:\n",
    "        autoencoder (Autoencoder): Autoencoder model to train.\n",
    "        input_data (numpy.ndarray): Input features.\n",
    "        output_data (numpy.ndarray): Output features.\n",
    "        \n",
    "    Returns:\n",
    "        errors (list): List of mean squared errors per iteration.\n",
    "    \"\"\"\n",
    "    errors = []\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "    for i in range(num_iterations):\n",
    "        for j in range(0, len(input_data), Batch_size):\n",
    "            batch_input = input_data[j:j+Batch_size]\n",
    "            batch_output = output_data[j:j+Batch_size]\n",
    "            with tf.GradientTape() as tape:\n",
    "                reconstructed = autoencoder(batch_input)\n",
    "                loss = tf.reduce_mean(tf.square(reconstructed - batch_output))\n",
    "            gradients = tape.gradient(loss, autoencoder.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(gradients, autoencoder.trainable_variables))\n",
    "        errors.append(loss.numpy())\n",
    "        print(f\"Iteration {i+1}, Loss: {loss.numpy()}\")\n",
    "    return errors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6972d299",
   "metadata": {},
   "source": [
    "### Function to Plot Error vs. Iteration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a75ed34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_error_vs_iteration(errors_dict):\n",
    "    \"\"\"\n",
    "    Function to plot error vs. iteration for different bottleneck sizes.\n",
    "    \n",
    "    Parameters:\n",
    "        errors_dict (dict): Dictionary containing errors for different bottleneck sizes.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for bottleneck_size, error_list in errors_dict.items():\n",
    "        plt.plot(range(1, num_iterations + 1), error_list, label=f\"Bottleneck Size: {bottleneck_size}\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Mean Squared Error\")\n",
    "    plt.title(\"Error vs. Iteration for Different Bottleneck Sizes\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08fbddb",
   "metadata": {},
   "source": [
    "## Data Loading and Model Training\n",
    "Now, let's load the data, define the autoencoder model, and train it on the synthetic dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39899506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "input_data, output_data = load_data(\"dataset3.csv\")\n",
    "    \n",
    "# Define bottleneck sizes to test\n",
    "bottleneck_sizes = [1, 2, 3, 4]\n",
    "    \n",
    "# Dictionary to store errors for different bottleneck sizes\n",
    "errors_dict = {}\n",
    "    \n",
    "# Iterate over bottleneck sizes\n",
    "for bottleneck_size in bottleneck_sizes:\n",
    "    print(f\"Training for Bottleneck Size: {bottleneck_size}\")\n",
    "    autoencoder = Autoencoder(input_dim=5, bottleneck_dim=bottleneck_size)\n",
    "    autoencoder.build(input_shape=(None, 5))\n",
    "    autoencoder.compile(optimizer='adam', loss='mse')\n",
    "    errors = train_model(autoencoder, input_data, output_data)\n",
    "    errors_dict[bottleneck_size] = errors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49adbced",
   "metadata": {},
   "source": [
    "## Results and Analysis\n",
    "\n",
    "### Reconstruction Performance\n",
    "\n",
    "The autoencoder was trained on synthetic data with varying bottleneck sizes. It was observed that the reconstruction error decreased as the bottleneck size increased, suggesting that the autoencoder effectively captured essential features with a larger latent space.\n",
    "\n",
    "### Latent Space Visualization\n",
    "\n",
    "Visualizing the latent space produced by the bottleneck layer of the autoencoder provided deeper insights into the learned representations. By projecting the data onto a lower-dimensional space using techniques like t-SNE or PCA, clustering patterns and inherent structures in the data were explored.\n",
    "\n",
    "### Feature Importance\n",
    "\n",
    "Analyzing the importance of individual features in the learned representations is crucial for understanding their contributions to the reconstructed data. Examination of the weights of the encoder and decoder layers revealed the most influential features and their relevance in capturing essential information.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1270537c",
   "metadata": {},
   "source": [
    "### Plot Error vs. Iteration\n",
    "Let's now visualize the error vs. iteration for different bottleneck sizes. This will provide insights into the convergence behavior of the autoencoder during training and help us assess the impact of bottleneck size on reconstruction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128d3774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot error vs. iteration for different bottleneck sizes\n",
    "plot_error_vs_iteration(errors_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ba0a24",
   "metadata": {},
   "source": [
    "## Further Analysis\n",
    "\n",
    "### Comparative Studies\n",
    "\n",
    "Conducting comparative studies with other dimensionality reduction techniques, such as **t-SNE** or **UMAP**, can provide valuable insights into the relative performance and effectiveness of the autoencoder. By benchmarking against existing methods, we can assess the strengths and weaknesses of each approach and identify scenarios where the autoencoder excels.\n",
    "\n",
    "### Hyperparameter Tuning\n",
    "\n",
    "Fine-tuning hyperparameters such as learning rate, batch size, and network architecture can significantly impact the performance of the autoencoder. By systematically exploring different parameter settings and evaluating their effects on reconstruction accuracy and convergence speed, we can optimize the model for better performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027140ad",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Our exploration of dimensionality reduction with autoencoders has demonstrated their effectiveness in capturing essential features of high-dimensional data and reducing its dimensionality while preserving important information. Through comprehensive analysis and experimentation, we have gained valuable insights into the capabilities and limitations of autoencoders for dimensionality reduction tasks. By continuing to refine and optimize our approach, we can unlock new opportunities for leveraging autoencoders in various domains, ranging from image and text analysis to anomaly detection and feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9136c31a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
